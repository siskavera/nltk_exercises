{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Review 1 on computing with language. How many words are there in text2? How many distinct words are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words: 141576\n",
      "No. of distinct words: 6833\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of words: %d\" % len(text2))\n",
    "print(\"No. of distinct words: %d\" % len(set(text2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Compare the lexical diversity scores for humor and romance fiction in 1.1. Which genre is more lexically diverse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Sense and Sensibility by Jane Austen 1811>: 0.048\n",
      "<Text: Monty Python and the Holy Grail>: 0.128\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    lex_div = len(set(text)) / len(text)\n",
    "    return lex_div\n",
    "\n",
    "print(\"%s: %.3f\" % (text2, lexical_diversity(text2)))\n",
    "print(\"%s: %.3f\" % (text6, lexical_diversity(text6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Produce a dispersion plot of the four main protagonists in Sense and Sensibility: Elinor, Marianne, Edward, and Willoughby. What can you observe about the different roles played by the males and females in this novel? Can you identify the couples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Elinor\",\"Marianne\",\"Edward\",\"Willoughby\"]\n",
    "\n",
    "text2.dispersion_plot(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Find the collocations in text5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanna chat; PART JOIN; MODE #14-19teens; JOIN PART; PART PART;\n",
      "cute.-ass MP3; MP3 player; JOIN JOIN; times .. .; ACTION watches; guys\n",
      "wanna; song lasts; last night; ACTION sits; -...)...- S.M.R.; Lime\n",
      "Player; Player 12%; dont know; lez gurls; long time\n"
     ]
    }
   ],
   "source": [
    "text5.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Review 2 on lists and strings.\n",
    "\n",
    "* Define a string and assign it to a variable, e.g., my_string = 'My String' (but put something more interesting in the string). Print the contents of this variable in two ways, first by simply typing the variable name and pressing enter, then by using the  print statement.\n",
    "\n",
    "* Try adding the string to itself using my_string + my_string, or multiplying it by a number, e.g., my_string * 3. Notice that the strings are joined together without any spaces. How could you fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vixen is a good dog.\n",
      "Vixen is a good dog.Vixen is a good dog.\n",
      "Vixen is a good dog.Vixen is a good dog.Vixen is a good dog.\n",
      "Vixen is a good dog. Vixen is a good dog. Vixen is a good dog.\n"
     ]
    }
   ],
   "source": [
    "my_string = 'Vixen is a good dog.'\n",
    "\n",
    "print(my_string)\n",
    "print(my_string + my_string)\n",
    "print(my_string * 3)\n",
    "print(' '.join([my_string] * 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Define a variable my_sent to be a list of words, using the syntax my_sent = [\"My\", \"sent\"] (but with your own words, or a favorite saying).\n",
    "* Use ' '.join(my_sent) to convert this into a string.\n",
    "* Use split() to split the string back into the list form you had to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vixen is a good dog\n",
      "['Vixen', 'is', 'a', 'good', 'dog']\n"
     ]
    }
   ],
   "source": [
    "my_sent = [\"Vixen\",\"is\",\"a\",\"good\",\"dog\"]\n",
    "\n",
    "print(' '.join(my_sent))\n",
    "print(' '.join(my_sent).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11\\.  Define several variables containing lists of words, e.g., phrase1, phrase2, and so on. Join them together in various combinations (using the plus operator) to form whole sentences. What is the relationship between len(phrase1 + phrase2) and  len(phrase1) + len(phrase2)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'the', '26th', 'Tomorrow', 'is', 'the', '27th']\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "phrase1 = [\"It\",\"is\",\"the\",\"26th\"]\n",
    "phrase2 = [\"Tomorrow\",\"is\",\"the\",\"27th\"]\n",
    "\n",
    "print(phrase1 + phrase2)\n",
    "print(len(phrase1+phrase2))\n",
    "print(len(phrase1) + len(phrase2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12\\. Consider the following two expressions, which have the same value. Which one will typically be more relevant in NLP? Why?\n",
    "* \"Monty Python\"[6:12]\n",
    "* [\"Monty\", \"Python\"][1]\n",
    "\n",
    "*The second, choosing a word*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13\\. We have seen how to represent a sentence as a list of words, where each word is a sequence of characters. What does  sent1[2][2] do? Why? Experiment with other index values.\n",
    "\n",
    "*It is the 3. letter of the 3. word.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vixen\n",
      "x\n"
     ]
    }
   ],
   "source": [
    "print(my_sent[0])\n",
    "print(my_sent[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14\\. The first sentence of text3 is provided to you in the variable sent3. The index of the in sent3 is 1, because sent3[1] gives us  'the'. What are the indexes of the two other occurrences of this word in sent3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth', '.']\n",
      "[1, 5, 8]\n",
      "['the', 'the', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(sent3)\n",
    "\n",
    "all_indices = [i for i, j in enumerate(sent3) if j == 'the']\n",
    "print(all_indices)\n",
    "\n",
    "print([sent3[i] for i in all_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15\\. Review the discussion of conditionals in 4. Find all words in the Chat Corpus (text5) starting with the letter b. Show them in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'b-day', 'b/c', 'b4', 'babay', 'babble', 'babblein', 'babe', 'babes', 'babi', 'babies', 'babiess', 'baby', 'babycakeses', 'bachelorette', 'back', 'backatchya', 'backfrontsidewaysandallaroundtheworld', 'backroom', 'backup', 'bacl', 'bad', 'bag', 'bagel', 'bagels', 'bahahahaa', 'bak', 'baked', 'balad', 'balance', 'balck', 'ball', 'ballin', 'balls', 'ban', 'band', 'bandito', 'bandsaw', 'banjoes', 'banned', 'baord', 'bar', 'barbie', 'bare', 'barely', 'bares', 'barfights', 'barks', 'barn', 'barrel', 'base', 'bases', 'basically', 'basket', 'battery', 'bay', 'bbbbbyyyyyyyeeeeeeeee', 'bbiam', 'bbl', 'bbs', 'bc', 'be', 'beach', 'beachhhh', 'beam', 'beams', 'beanbag', 'beans', 'bear', 'bears', 'beat', 'beaten', 'beatles', 'beats', 'beattles', 'beautiful', 'because', 'beckley', 'become', 'bed', 'bedford', 'bedroom', 'beeeeehave', 'beeehave', 'been', 'beer', 'before', 'beg', 'begin', 'behave', 'behind', 'bein', 'being', 'beleive', 'believe', 'belive', 'bell', 'belly', 'belong', 'belongings', 'ben', 'bend', 'benz', 'bes', 'beside', 'besides', 'best', 'bet', 'betrayal', 'betta', 'better', 'between', 'beuty', 'bf', 'bi', 'biatch', 'bible', 'biebsa', 'bied', 'big', 'bigest', 'biggest', 'biiiatch', 'bike', 'bikes', 'bikini', 'bio', 'bird', 'birfday', 'birthday', 'bisexual', 'bishes', 'bit', 'bitch', 'bitches', 'bitdh', 'bite', 'bites', 'biyatch', 'biz', 'bj', 'black', 'blade', 'blah', 'blank', 'blankie', 'blazed', 'bleach', 'blech', 'bless', 'blessings', 'blew', 'blind', 'blinks', 'bliss', 'blocking', 'bloe', 'blood', 'blooded', 'bloody', 'blow', 'blowing', 'blowjob', 'blowup', 'blue', 'blueberry', 'bluer', 'blues', 'blunt', 'board', 'bob', 'bodies', 'body', 'boed', 'boght', 'boi', 'boing', 'boinked', 'bois', 'bomb', 'bone', 'boned', 'bones', 'bong', 'boning', 'bonus', 'boo', 'booboo', 'boobs', 'book', 'boom', 'boooooooooooglyyyyyy', 'boost', 'boot', 'bootay', 'booted', 'boots', 'booty', 'border', 'borderline', 'bored', 'boredom', 'boring', 'born', 'born-again', 'bosom', 'boss', 'bossy', 'bot', 'both', 'bother', 'bothering', 'bottle', 'bought', 'bounced', 'bouncer', 'bouncers', 'bound', 'bout', 'bouts', 'bow', 'bowl', 'box', 'boy', 'boyfriend', 'boys', 'bra', 'brad', 'brady', 'brain', 'brakes', 'brass', 'brat', 'brb', 'brbbb', 'bread', 'break', 'breaks', 'breath', 'breathe', 'bred', 'breeding', 'bright', 'brightened', 'bring', 'brings', 'bro', 'broke', 'brooklyn', 'brother', 'brothers', 'brought', 'brown', 'brrrrrrr', 'bruises', 'brunswick', 'brwn', 'btw', 'bucks', 'buddyyyyyy', 'buff', 'buffalo', 'bug', 'bugs', 'buh', 'build', 'builds', 'built', 'bull', 'bulls', 'bum', 'bumber', 'bummer', 'bumped', 'bumper', 'bunch', 'bunny', 'burger', 'burito', 'burned', 'burns', 'burp', 'burpin', 'burps', 'burried', 'burryed', 'bus', 'buses', 'bust', 'busted', 'busy', 'but', 'butt', 'butter', 'butterscotch', 'button', 'buttons', 'buy', 'buying', 'bwahahahahahahahahahaha', 'by', 'byb', 'bye', 'byeee', 'byeeee', 'byeeeeeeee', 'byeeeeeeeeeeeee', 'byes']\n"
     ]
    }
   ],
   "source": [
    "b_words = [word for word in sorted(set(text5)) if len(word) > 0 and word[0] == 'b']\n",
    "print(b_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16\\. Type the expression list(range(10)) at the interpreter prompt. Now try list(range(10, 20)), list(range(10, 20, 2)), and  list(range(20, 10, -2)). We will see a variety of uses for this built-in function in later chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[10, 12, 14, 16, 18]\n",
      "[20, 18, 16, 14, 12]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(10)))\n",
    "print(list(range(10, 20)))\n",
    "print(list(range(10, 20, 2)))\n",
    "print(list(range(20, 10, -2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Medium difficulty-level from now on :D**\n",
    "\n",
    "17\\. Use text9.index() to find the index of the word sunset. You'll need to insert this word as an argument between the parentheses. By a process of trial and error, find the slice for the complete sentence that contains this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629\n",
      "THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "i_sunset = text9.index('sunset')\n",
    "print(i_sunset)\n",
    "\n",
    "n_before = 8\n",
    "n_after = 14\n",
    "print(' '.join(text9[i_sunset-n_before:i_sunset+n_after+1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18\\. Using list addition, and the set and sorted operations, compute the vocabulary of the sentences sent1 ... sent8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "['!', ',', '-', '.', '1', '25', '29', '61', ':', 'ARTHUR', 'Call', 'Citizens', 'Dashwood', 'Fellow', 'God', 'House', 'I', 'In', 'Ishmael', 'JOIN', 'KING', 'MALE', 'Nov.', 'PMing', 'Pierre', 'Representatives', 'SCENE', 'SEXY', 'Senate', 'Sussex', 'The', 'Vinken', 'Whoa', '[', ']', 'a', 'and', 'as', 'attrac', 'been', 'beginning', 'board', 'clop', 'created', 'director', 'discreet', 'earth', 'encounters', 'family', 'for', 'had', 'have', 'heaven', 'in', 'join', 'lady', 'lol', 'long', 'me', 'nonexecutive', 'of', 'old', 'older', 'people', 'problem', 'seeks', 'settled', 'single', 'the', 'there', 'to', 'will', 'wind', 'with', 'years']\n"
     ]
    }
   ],
   "source": [
    "joined = sent1 + sent2 + sent3 + sent4 + sent5 + sent6 + sent7 + sent8\n",
    "print(len(set(joined)))\n",
    "print(sorted(set(joined)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19\\. What is the difference between the following two lines? Which one will give a larger value? Will this be the case for other texts?\n",
    "* `sorted(set(w.lower() for w in text1))`\n",
    "* `sorted(w.lower() for w in set(text1))`\n",
    "\n",
    "*Second will (possibly) give a larger value, since upper- and lower-case letters are different symbols when the set conversion is performed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17231\n",
      "19317\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted(set(w.lower() for w in text1))))\n",
    "print(len(sorted(w.lower() for w in set(text1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20\\. What is the difference between the following two tests: w.isupper() and not w.islower()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  w.isupper() not w.islower()\n",
      "WORD: 1 1\n",
      "Word: 0 1\n",
      "word: 0 0\n",
      ".: 0 1\n"
     ]
    }
   ],
   "source": [
    "words = ['WORD','Word','word','.']\n",
    "\n",
    "print('w:  w.isupper() not w.islower()')\n",
    "for word in words:\n",
    "    print(\"%s: %d %d\" % (word, word.isupper(), not word.islower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21\\. Write the slice expression that extracts the last two words of text2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE', 'END']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22\\. Find all the four-letter words in the Chat Corpus (text5). With the help of a frequency distribution (FreqDist), show these words in decreasing order of frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 1181 samples and 10204 outcomes>\n",
      "[('JOIN', 1021), ('PART', 1016), ('that', 274), ('what', 183), ('here', 181), ('....', 170), ('have', 164), ('like', 156), ('with', 152), ('chat', 142), ('your', 137), ('good', 130), ('just', 125), ('lmao', 107), ('know', 103), ('room', 98), ('from', 92), ('this', 86), ('well', 81), ('hiya', 78)]\n"
     ]
    }
   ],
   "source": [
    "four_letter_words = [w for w in text5 if len(w) == 4]\n",
    "four_letter_f = FreqDist(four_letter_words)\n",
    "\n",
    "print(four_letter_f)\n",
    "print(four_letter_f.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23\\. Review the discussion of looping with conditions in 4. Use a combination of for and if statements to loop over the words of the movie script for Monty Python and the Holy Grail (text6) and print all the uppercase words, one per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOVELY\n",
      "OLD\n",
      "A\n",
      "PRISONER\n",
      "O\n",
      "KNIGHTS\n",
      "OFFICER\n",
      "GREEN\n",
      "OF\n",
      "PRINCESS\n",
      "DENNIS\n",
      "KNIGHT\n",
      "I\n",
      "SCENE\n",
      "ALL\n",
      "VILLAGERS\n",
      "SECOND\n",
      "BRIDGEKEEPER\n",
      "LEFT\n",
      "MAYNARD\n",
      "DEAD\n",
      "ENCHANTER\n",
      "HERBERT\n",
      "CAMERAMAN\n",
      "AMAZING\n",
      "BEDEVERE\n",
      "RIGHT\n",
      "VILLAGER\n",
      "WITCH\n",
      "WINSTON\n",
      "CHARACTERS\n",
      "SHRUBBER\n",
      "MAN\n",
      "CROWD\n",
      "STUNNER\n",
      "CRONE\n",
      "CUSTOMER\n",
      "FRENCH\n",
      "GUEST\n",
      "ANIMATOR\n",
      "HEAD\n",
      "U\n",
      "CRASH\n",
      "LAUNCELOT\n",
      "OTHER\n",
      "LUCKY\n",
      "ARTHUR\n",
      "CRAPPER\n",
      "GUARD\n",
      "DINGO\n",
      "MINSTREL\n",
      "TIM\n",
      "PERSON\n",
      "C\n",
      "MIDDLE\n",
      "CART\n",
      "BRIDE\n",
      "RANDOM\n",
      "CARTOON\n",
      "MASTER\n",
      "BROTHER\n",
      "INSPECTOR\n",
      "B\n",
      "PIGLET\n",
      "S\n",
      "GALAHAD\n",
      "WIFE\n",
      "GUARDS\n",
      "HISTORIAN\n",
      "ARMY\n",
      "MONKS\n",
      "GOD\n",
      "THE\n",
      "SUN\n",
      "PRINCE\n",
      "VOICE\n",
      "CHARACTER\n",
      "MIDGET\n",
      "NI\n",
      "BLACK\n",
      "GIRLS\n",
      "N\n",
      "SOLDIER\n",
      "ROGER\n",
      "SIR\n",
      "PARTY\n",
      "PATSY\n",
      "Y\n",
      "FATHER\n",
      "ROBIN\n",
      "SENTRY\n",
      "W\n",
      "NARRATOR\n",
      "DIRECTOR\n",
      "BORS\n",
      "ZOOT\n",
      "KING\n",
      "CONCORDE\n",
      "HEADS\n",
      "GUESTS\n",
      "WOMAN\n"
     ]
    }
   ],
   "source": [
    "for word in set(text6):\n",
    "    if word.isupper():\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24\\. Write expressions for finding all words in text6 that meet the conditions listed below. The result should be in the form of a list of words: ['word1', 'word2', ...].\n",
    "\n",
    "* Ending in ize\n",
    "* Containing the letter z\n",
    "* Containing the sequence of letters pt\n",
    "* Having all lowercase letters except for an initial capital (i.e., titlecase)\n",
    "\n",
    "*There was none...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "good_words = [w for w in set(text6) if len(w) > 2 and w[-3:] == 'ize' and 'pt' in w and w[1:].islower()]\n",
    "print(good_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25\\. Define sent to be the list of words ['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']. Now write code to perform the following tasks:\n",
    "\n",
    "* Print all words beginning with sh\n",
    "* Print all words longer than four characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'shells', 'shore']\n",
      "['sells', 'shells', 'shore']\n"
     ]
    }
   ],
   "source": [
    "sent = ['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']\n",
    "\n",
    "print([w for w in sent if w[0:2] == 'sh'])\n",
    "print([w for w in sent if len(w) > 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26\\. What does the following Python code do?  sum(len(w) for w in text1) Can you use it to work out the average word length of a text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of text (sum of words): 999044\n",
      "Average word length: 3.830\n"
     ]
    }
   ],
   "source": [
    "print(\"Total length of text (sum of words): %d\" % sum(len(w) for w in text1))\n",
    "print(\"Average word length: %.3lf\" % (sum(len(w) for w in text1)/len(text1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27\\. Define a function called vocab_size(text) that has a single parameter for the text, and which returns the vocabulary size of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19317\n"
     ]
    }
   ],
   "source": [
    "def vocab_size(text):\n",
    "    return len(set(text))\n",
    "\n",
    "print(vocab_size(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28\\. Define a function percent(word, text) that calculates how often a given word occurs in a text, and expresses the result as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027271571452788607\n",
      "0.004831327343617562\n"
     ]
    }
   ],
   "source": [
    "def percent(word, text):\n",
    "    n_occ = text.count(word)\n",
    "    return n_occ/len(text)\n",
    "\n",
    "print(percent('the', text2))\n",
    "print(percent('Elinor', text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29\\. We have been using sets to store vocabularies. Try the following Python expression: set(sent3) < set(text1). Experiment with this using different arguments to set(). What does it do? Can you think of a practical application for this?\n",
    "\n",
    "*Returns true if set1 is subset of set2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'problem', 'with', 'people', 'PMing', 'me', 'to', 'lol', 'JOIN']\n",
      "<Text: Moby Dick by Herman Melville 1851>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def experimenter(text1, text2):\n",
    "    print(text1)\n",
    "    print(text2)\n",
    "    print(set(text1) < set(text2))\n",
    "\n",
    "experimenter(sent5, text1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
