{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "languages = ['Chickasaw', 'English', 'German_Deutsch',\n",
    "    'Greenlandic_Inuktikut', 'Hungarian_Magyar', 'Ibibio_Efik']\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "          (lang, len(word))\n",
    "          for lang in languages\n",
    "          for word in udhr.words(lang + '-Latin1'))\n",
    "cfd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_text = udhr.raw('Hungarian_Magyar-Latin1')\n",
    "raw_fd = nltk.FreqDist(raw_text)\n",
    "raw_fd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "corpus_root = 'texts'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*')\n",
    "wordlists.fileids()\n",
    "wordlists.words('aranyszoru_barany.txt')\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (fileid, len(word))\n",
    "    for fileid in wordlists.fileids()\n",
    "    for word in wordlists.words(fileid))\n",
    "cfd.plot(cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the news and romance genres from the Brown Corpus, find out which days of the week are most newsworthy, and which are most romantic. Define a variable called days containing a list of days of the week, i.e. ['Monday', ...]. Now tabulate the counts for these words using cfd.tabulate(samples=days). Now try the same thing using plot in place of tabulate. You may control the output order of days with the help of an extra parameter: samples=['Monday', ...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "genre_word = [(genre, word) \n",
    "              for genre in ['news','romance'] \n",
    "              for word in brown.words(categories = genre)]\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "#cpd = nltk.ConditionalProbDist(genre_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Monday   Tuesday Wednesday  Thursday    Friday  Saturday    Sunday \n",
      "   news        54        43        22        20        41        33        51 \n",
      "romance         2         3         3         1         3         4         5 \n"
     ]
    }
   ],
   "source": [
    "cfd.tabulate(samples = days)\n",
    "cfd.plot(samples = days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating random text with bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gott der HERR , und sprach : Ich will ich will ich will ich will "
     ]
    }
   ],
   "source": [
    "def generate_model(cfdist, word, num = 15):\n",
    "    for i in range(num):\n",
    "        print(word, end = ' ')\n",
    "        word = cfdist[word].max()\n",
    "\n",
    "text = nltk.corpus.genesis.words('german.txt')\n",
    "bigrams = nltk.bigrams(text)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "generate_model(cfd, 'Gott')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['english-kjv.txt',\n",
       " 'english-web.txt',\n",
       " 'finnish.txt',\n",
       " 'french.txt',\n",
       " 'german.txt',\n",
       " 'lolcat.txt',\n",
       " 'portuguese.txt',\n",
       " 'swedish.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.genesis.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet\n",
    "\n",
    "Write down all the senses of the word dish that you can think of. Now, explore this word with the help of WordNet, using the same operations we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dish.n.01')\n",
      "['dish']\n",
      "a piece of dishware normally used as a container for holding or serving food\n",
      "\n",
      "Synset('dish.n.02')\n",
      "['dish']\n",
      "a particular item of prepared food\n",
      "\n",
      "Synset('dish.n.03')\n",
      "['dish', 'dishful']\n",
      "the quantity that a dish will hold\n",
      "\n",
      "Synset('smasher.n.02')\n",
      "['smasher', 'stunner', 'knockout', 'beauty', 'ravisher', 'sweetheart', 'peach', 'lulu', 'looker', 'mantrap', 'dish']\n",
      "a very attractive or seductive looking woman\n",
      "\n",
      "Synset('dish.n.05')\n",
      "['dish', 'dish_aerial', 'dish_antenna', 'saucer']\n",
      "directional antenna consisting of a parabolic reflector for microwave or radio frequency radiation\n",
      "\n",
      "Synset('cup_of_tea.n.01')\n",
      "['cup_of_tea', 'bag', 'dish']\n",
      "an activity that you like or at which you are superior\n",
      "\n",
      "Synset('serve.v.06')\n",
      "['serve', 'serve_up', 'dish_out', 'dish_up', 'dish']\n",
      "provide (usually but not necessarily food)\n",
      "\n",
      "Synset('dish.v.02')\n",
      "['dish']\n",
      "make concave; shape like a dish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('dish'):\n",
    "    print(synset)\n",
    "    print(synset.lemma_names())\n",
    "    print(synset.definition())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('adobo.n.01')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_of_dishes = wn.synset('dish.n.02').hyponyms()\n",
    "types_of_dishes[0]\n",
    "sorted(lemma.name() for synset in types_of_dishes for lemma in synset.lemmas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a boxer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "someone who fights with his fists for sport\n",
      "['boxer', 'pugilist']\n",
      "boxer.n.01\n",
      "\n",
      "a workman employed to pack things into containers\n",
      "['packer', 'bagger', 'boxer']\n",
      "packer.n.01\n",
      "\n",
      "a member of a nationalistic Chinese secret society that led an unsuccessful rebellion in 1900 against foreign interests in China\n",
      "['Boxer']\n",
      "boxer.n.03\n",
      "\n",
      "a breed of stocky medium-sized short-haired dog with a brindled coat and square-jawed muzzle developed in Germany\n",
      "['boxer']\n",
      "boxer.n.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('boxer'):\n",
    "    print(synset.definition())\n",
    "    print(synset.lemma_names())\n",
    "    print(synset.name())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('organism.n.01')]\n",
      "0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "boxer = wn.synset('boxer.n.04')\n",
    "fighter = wn.synset('boxer.n.01')\n",
    "\n",
    "print(boxer.lowest_common_hypernyms(fighter))\n",
    "print(boxer.path_similarity(fighter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Use the corpus module to explore austen-persuasion.txt. How many word tokens does this book have? How many word types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of words: 98171\n",
      "No. of word types: 6132\n",
      "Displaying 23 of 23 matches:\n",
      "re upon , that it will not greatly surprise me if , with all our caution , som\n",
      "was the reply , and with a look of surprise . \" Yes ; it is in two points offe\n",
      "t all hours , that it was rather a surprise to her to find Mary alone ; but be\n",
      " , food , hours , & c ., and their surprise at his accounts , at learning the \n",
      " , who was lying on the sofa . The surprise of finding himself almost alone wi\n",
      "rt of the street ; but his evident surprise and vexation at the substitution o\n",
      "h amusement at his little start of surprise , that he had not been at all awar\n",
      "think differently ; and it did not surprise her , therefore , that Lady Russel\n",
      " and , to quicken the pleasure and surprise , with Admiral and Mrs Croft ' s c\n",
      "you shall hear something that will surprise you . But first of all , you must \n",
      "ildering , first effects of strong surprise were over with her . Still , howev\n",
      " to feign that he was . It did not surprise , but it grieved Anne to observe t\n",
      "hing to encounter Lady Russell ' s surprise ; and now , if she were by any cha\n",
      "attaching himself to her with some surprise . Had it been the effect of gratit\n",
      " be Lady Elliot , and as general a surprise that Miss Elliot should be apparen\n",
      " , Anne could not but express some surprise at Mrs Smith ' s having spoken of \n",
      "ove \" were ushered into the room . Surprise was the strongest emotion raised b\n",
      "uisa at Uppercross . Anne ' s only surprise was , that affairs should be in fo\n",
      " latter could not be more than the surprise of the moment . It was impossible \n",
      "ff on the other ; and checking the surprise which she could not but feel at su\n",
      " a manner of doubtful meaning , of surprise rather than gratification , of pol\n",
      " think , Miss Elliot , to my great surprise I met with Mr Elliot in Bath Stree\n",
      "use could have conceived . All the surprise and suspense , and every other pai\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "persuasion = nltk.corpus.gutenberg.words('austen-persuasion.txt')\n",
    "\n",
    "print(\"No. of words: %d\" % len(persuasion))\n",
    "print(\"No. of word types: %d\" % len(set(persuasion)))\n",
    "\n",
    "print(nltk.Text(persuasion).concordance('surprise'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Read in the texts of the State of the Union addresses, using the state_union corpus reader. Count occurrences of men, women, and people in each document. What has happened to the usage of these words over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1945 1946 1947 1948 1949 1950 1951 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 \n",
      "   men    2   12    7    5    2    6    8    3    2    4    2    5    2    4    2    6    6    8    3   19   12   11    4    5    2    1    1    1    0    0    3    2    0    0    1    1    1    3    3    1    2    1    1    2    3    9    4    1    1    1    2    1    2    2    5    4    3    6    7    8    7 \n",
      "people   10   49   12   22   15   15   10   17   15   26   30   11   19   11   10   10   10   15    3   30   35   25   17    6   23   32    7    9   20   14   18   19   26   15   12   11   17   19   27   12   14   24   17   13    9   27   27   45   66   73   43   31   22   22   41   27   14   33   21   18   22 \n",
      " women    2    7    2    1    1    2    2    0    0    0    2    2    1    1    0    0    2    5    1    3    1    1    0    2    0    0    0    0    0    0    1    1    1    1    2    1    2    7    5    1    2    0    0    3    2    9    4    2    1    3    3    2    2    3    7    6    6    4    8   11    7 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import state_union\n",
    "\n",
    "words = ['men','women','people']\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (word.lower(), file[0:4])\n",
    "    for file in state_union.fileids()\n",
    "    for word in state_union.words(file)\n",
    "    for target in words\n",
    "    if word.lower() == target)\n",
    "\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Investigate the holonym-meronym relations for some nouns. Remember that there are three kinds of holonym-meronym relation, so you need to use: member_meronyms(), part_meronyms(), substance_meronyms(), member_holonyms(),  part_holonyms(), and substance_holonyms()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the digits of the foot\n",
      "[Synset('tiptoe.n.01'), Synset('toenail.n.01')]\n",
      "[]\n",
      "[]\n",
      "[Synset('foot.n.01')]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "my_lemma = 'toe.n.01'\n",
    "print(wn.synset(my_lemma).definition())\n",
    "\n",
    "print(wn.synset(my_lemma).part_meronyms())\n",
    "print(wn.synset(my_lemma).substance_meronyms())\n",
    "print(wn.synset(my_lemma).member_meronyms())\n",
    "\n",
    "print(wn.synset(my_lemma).part_holonyms())\n",
    "print(wn.synset(my_lemma).substance_holonyms())\n",
    "print(wn.synset(my_lemma).member_holonyms())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. In the discussion of comparative wordlists, we created an object called translate which you could look up using words in both German and Spanish in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Tier\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import swadesh\n",
    "\n",
    "es2de = swadesh.entries(['es','de'])\n",
    "translate = dict(es2de)\n",
    "\n",
    "en2de = swadesh.entries(['en','de'])\n",
    "translate.update(dict(en2de))\n",
    "\n",
    "# duplicate entry!\n",
    "print(\"Original: %s\" % translate['animal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('es', 'ich')]\n"
     ]
    }
   ],
   "source": [
    "# Could use dictionaries separately, pre- or suffix the words, or have entries\n",
    "# point to a list of translations, having language info\n",
    "\n",
    "# List\n",
    "es2de = [(entry[0],[('es',entry[1])]) for entry in swadesh.entries(['es','de'])]\n",
    "en2de = [(entry[0],[('en',entry[1])]) for entry in swadesh.entries(['en','de'])]\n",
    "\n",
    "langspec_translate = dict(es2de)\n",
    "for entry in en2de:\n",
    "    if entry[0] in langspec_translate:\n",
    "        langspec_translate[entry[0]].extend(entry[1])\n",
    "    else:\n",
    "        langspec_translate[entry[0]] = entry[1]\n",
    "\n",
    "# duplicate entry!\n",
    "print(langspec_translate['yo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Strunk and White's Elements of Style, the word however, used at the start of a sentence, means \"in whatever way\" or \"to whatever extent\", and not \"nevertheless\". They give this example of correct usage: However you advise him, he will probably do as he thinks best. (http://www.bartleby.com/141/strunk3.html) Use the concordance tool to study actual usage of this word in the various texts we have been considering. See also the LanguageLog posting \"Fossilized prejudices about 'however'\" at  http://itre.cis.upenn.edu/~myl/languagelog/archives/001913.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma\n",
      "\n",
      "Displaying 25 of 131 matches:\n",
      " her many enjoyments . The danger , however , was at present so unperceived , t\n",
      "ion would offend . Miss Churchill , however , being of age , and with the full \n",
      "n . From the expense of the child , however , he was soon relieved . The boy ha\n",
      " -- and been very well brought up . However , I do not mean to set up my opinio\n",
      "f and predict . It was not likely , however , that any body should have equalle\n",
      "to be borne . We will not despair , however . Weston may grow cross from the wa\n",
      "is so very handsome and agreeable . However , I do really think Mr . Martin a v\n",
      " accepted after all . This letter , however , was written , and sealed , and se\n",
      "e him .\" \" And if I did , ( which , however , I am far from allowing ) I should\n",
      " slightingly . Waiving that point , however , and supposing her to be , as you \n",
      "e was not so materially cast down , however , but that a little time and the re\n",
      "ld inspire him .\" The very next day however produced some proof of inspiration \n",
      "and staid to look through herself ; however , she called me back presently , an\n",
      "t turn up . His ostensible reason , however , was to ask whether Mr . Woodhouse\n",
      "l and cross . This does not apply , however , to Miss Bates ; she is only too g\n",
      "and sufferings of the poor family , however , were the first subject on meeting\n",
      "ting for her . She gained on them , however , involuntarily : the child ' s pac\n",
      "ould close it . It was not closed , however , it still remained ajar ; but by e\n",
      " believes himself secure .\" Still , however , though every thing had not been a\n",
      "ght advance rapidly if they would , however ; they must advance somehow or othe\n",
      " offence came not . The beginning , however , of every visit displayed none but\n",
      "eed !-- and my memory is very bad . However , it was an exceeding good , pretty\n",
      "first day . Emma ' s sense of right however had decided it ; and besides the co\n",
      "le fatigued . I could have wished , however , as you know , that you had seen M\n",
      "\" Our little friend Harriet Smith , however , is just such another pretty kind \n",
      "\n",
      "Persuasion\n",
      "\n",
      "Displaying 25 of 89 matches:\n",
      "onceited , silly father . She had , however , one very intimate friend , a sens\n",
      "early custom . But these measures , however good in themselves , were insuffici\n",
      "ellynch Hall was to be let . This , however , was a profound secret , not to be\n",
      "t immediate neighbourhood , which , however , had not suited him ; that acciden\n",
      "e dues of a tenant . It succeeded , however ; and though Sir Walter must ever l\n",
      "h , the former curate of Monkford , however suspicious appearances may be , but\n",
      "good character and appearance ; and however Lady Russell might have asked yet f\n",
      "siness no evil . She was assisted , however , by that perfect indifference and \n",
      "h the others . Something occurred , however , to give her a different duty . Ma\n",
      " , but can never alter plain ones . However , at any rate , as I have a great d\n",
      "l what is due to you as my sister . However , we may as well go and sit with th\n",
      "o means of her going . She wished , however to see the Crofts , and was glad to\n",
      "ithout any approach to coarseness , however , or any want of good humour . Anne\n",
      "ll be in question . She could not , however , reach such a degree of certainty \n",
      "al to Anne ' s nerves . She found , however , that it was one to which she must\n",
      "re gone , she hoped , to be happy , however oddly constructed such happiness mi\n",
      "once more in the same room . Soon , however , she began to reason with herself \n",
      " ! It would be but a new creation , however , and I never think much of your ne\n",
      "rove of Uppercross .\" Her husband , however , would not agree with her here ; f\n",
      "re presently .\" Captain Wentworth , however , came from his window , apparently\n",
      "d Walter stir . In another moment , however , she found herself in the state of\n",
      " at once . After a short struggle , however , Charles Hayter seemed to quit the\n",
      "rything being to be done together , however undesired and inconvenient . She tr\n",
      " , nobody answered her . Winthrop , however , or its environs -- for young men \n",
      "fore they were beyond her hearing , however , Louisa spoke again . \" Mary is go\n",
      "\n",
      "Hamlet\n",
      "\n",
      "No matches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "emma = nltk.Text(gutenberg.words('austen-emma.txt'))\n",
    "persuasion = nltk.Text(gutenberg.words('austen-persuasion.txt'))\n",
    "hamlet = nltk.Text(gutenberg.words('shakespeare-hamlet.txt'))\n",
    "\n",
    "print('Emma')\n",
    "print()\n",
    "emma.concordance(\"however\")\n",
    "print()\n",
    "\n",
    "print('Persuasion')\n",
    "print()\n",
    "persuasion.concordance(\"however\")\n",
    "print()\n",
    "\n",
    "print('Hamlet')\n",
    "print()\n",
    "hamlet.concordance(\"however\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Define a conditional frequency distribution over the Names corpus that allows you to see which initial letters are more frequent for males vs. females (cf. 4.4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5001, 2943]\n"
     ]
    }
   ],
   "source": [
    "names = nltk.corpus.names\n",
    "\n",
    "print([len(names.words(fileid)) for fileid in names.fileids()])\n",
    "\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (fileid, name[0])\n",
    "    for fileid in names.fileids()\n",
    "    for name in names.words(fileid))\n",
    "\n",
    "cfd.plot()\n",
    "# Weirdly very much not uniform!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Pick a pair of texts and study the differences between them, in terms of vocabulary, vocabulary richness, genre, etc. Can you find pairs of words which have quite different meanings across the two texts, such as monstrous in Moby Dick and in Sense and Sensibility?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd\n",
    "\n",
    "def vocab_size(words):\n",
    "    return(len(set(words)))\n",
    "\n",
    "def vocab_richness(words):\n",
    "    n_words = len(words)\n",
    "    n_distinct = len(set(words))\n",
    "    return(n_distinct/n_words)\n",
    "\n",
    "def mean_sent_len(sentences):\n",
    "    n_sents = len(sentences)\n",
    "    \n",
    "    total_n_words = 0\n",
    "    for sent in sentences:\n",
    "        total_n_words = total_n_words + len(sent)\n",
    "    \n",
    "    return(total_n_words/n_sents)\n",
    "\n",
    "def count_in_text(text, pattern):\n",
    "    n_occ = 0\n",
    "    for word in text:\n",
    "        if word == pattern:\n",
    "            n_occ += 1\n",
    "    return(n_occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>mean_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austen-sense.txt</td>\n",
       "      <td>sense</td>\n",
       "      <td>6833</td>\n",
       "      <td>0.048264</td>\n",
       "      <td>28.329066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>melville-moby_dick.txt</td>\n",
       "      <td>moby_dick</td>\n",
       "      <td>19317</td>\n",
       "      <td>0.074063</td>\n",
       "      <td>25.932896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file       name  vocab_size  vocab_richness  \\\n",
       "0        austen-sense.txt      sense        6833        0.048264   \n",
       "1  melville-moby_dick.txt  moby_dick       19317        0.074063   \n",
       "\n",
       "   mean_sent_len  \n",
       "0      28.329066  \n",
       "1      25.932896  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "my_files = ['austen-sense.txt', 'melville-moby_dick.txt']\n",
    "my_names = ['sense','moby_dick']\n",
    "\n",
    "df = pd.DataFrame({'name': my_names, 'file': my_files})\n",
    "\n",
    "v_vocab_size = []\n",
    "v_vocab_richness = []\n",
    "v_mean_sent_len = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    words = nltk.Text(gutenberg.words(row['file']))\n",
    "    sents = nltk.Text(gutenberg.sents(row['file']))\n",
    "    \n",
    "    v_vocab_size.append(vocab_size(words))\n",
    "    v_vocab_richness.append(vocab_richness(words))\n",
    "    v_mean_sent_len.append(mean_sent_len(sents))\n",
    "\n",
    "df['vocab_size'] = v_vocab_size\n",
    "df['vocab_richness'] = v_vocab_richness\n",
    "df['mean_sent_len'] = v_mean_sent_len\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sense = nltk.Text(gutenberg.words('austen-sense.txt'))\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "\n",
    "overlapping_words = set(sense).intersection(set(moby))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sense</th>\n",
       "      <th>moby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>office</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heath</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connected</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>progress</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temporary</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wild</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>familiarly</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shoulder</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mourning</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speculative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  sense  moby\n",
       "0       office      6     8\n",
       "1        heath      1     1\n",
       "2    connected      6    12\n",
       "3     progress      3     4\n",
       "4    temporary      3    11\n",
       "5         wild      4    82\n",
       "6   familiarly      2     5\n",
       "7     shoulder      2    12\n",
       "8     mourning      1     2\n",
       "9  speculative      1     1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_table = pd.DataFrame({'word': list(overlapping_words)}).head(10)\n",
    "\n",
    "n_sense = word_table.apply(lambda row: count_in_text(sense, row['word']), axis = 1)\n",
    "n_moby = word_table.apply(lambda row: count_in_text(moby, row['word']), axis = 1)\n",
    "\n",
    "word_table['sense'] = n_sense\n",
    "word_table['moby'] = n_moby\n",
    "\n",
    "word_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 42 matches:\n",
      "everal weeks in the house before he engaged much of Mrs . Dashwood ' s attentio\n",
      "he truth . \" And you really are not engaged to him !\" said she . \" Yet it certa\n",
      "ven to Norland half its charms were engaged in again with far greater enjoyment\n",
      "vided attention where his heart was engaged , and in slighting too easily the f\n",
      "ment she doubted not of their being engaged to each other ; and the belief of i\n",
      "ered her mind of their being really engaged , and this doubt was enough to prev\n",
      "k , to call on Lady Middleton .\" He engaged to be with them by four o ' clock .\n",
      "ceal their engagement ( if they ARE engaged ) from Mrs . Smith -- and if that i\n",
      "he , \" whether she is or she is not engaged to Willoughby ? From you , her moth\n",
      "osing it possible that they are not engaged , what distress would not such an e\n",
      "silent , till a new object suddenly engaged her attention . She was sitting by \n",
      "Lady Middleton ' s good opinion was engaged in their favour before they had bee\n",
      " of long standing ?\" \" We have been engaged these four years .\" \" Four years !\"\n",
      "and her companion ' s falsehood --\" Engaged to Mr . Edward Ferrars !-- I confes\n",
      "ith it . \" Four years you have been engaged ,\" said she with a firm voice . \" Y\n",
      "e , and , with the utmost harmony , engaged in forwarding the same work . The p\n",
      "ry long absence since we were first engaged , and it has stood the trial so wel\n",
      "o conduct the affair , they must be engaged . This conviction , though not enti\n",
      "that Mrs . Jennings , by being much engaged in her own room , could see little \n",
      " spirits , and the thoughts of both engaged elsewhere . Elinor wished very much\n",
      "and in whatever shop the party were engaged , her mind was equally abstracted f\n",
      " neither came nor wrote . They were engaged about the end of that time to atten\n",
      "a persuasion of my sister ' s being engaged to Mr . Willoughby ? I thought it h\n",
      "d that my affections have been long engaged elsewhere , and it will not be many\n",
      " ,\" she added , \" to be as solemnly engaged to him , as if the strictest legal \n",
      "None\n",
      "Displaying 18 of 18 matches:\n",
      "ty of line withdrawn from the boats engaged in the capture of this one whale , \n",
      " a totally different air from those engaged in regular voyage .\" -- CURRENTS AN\n",
      " , that this harpooneer is actually engaged this blessed Saturday night , or ra\n",
      "night clean into the holy Sabbath , engaged in such a cannibal business as sell\n",
      "tures that were in it . Thus I soon engaged his interest ; and from that we wen\n",
      "hemselves ; the mates were actively engaged ; and several of the shore people w\n",
      " I say , might now be seen actively engaged in looking over the bows for the ap\n",
      "f business ; and that when actively engaged therein , we are surrounded by all \n",
      "with an indifferent air ; and while engaged in the most imminent crisis of the \n",
      "nd collected as a journeyman joiner engaged for the year . Good - humored , eas\n",
      " Jeroboam ' s whaling voyage . They engaged him ; but straightway upon the ship\n",
      "orpse . While the two headsmen were engaged in making fast cords to his flukes \n",
      "activity of the other boats , still engaged in drugging the whales on the front\n",
      "e Frenchman ' s boats , then , were engaged in towing the ship one way , Stubb \n",
      "ty hours on the stretch , they were engaged in the boats , steadily pulling , o\n",
      " rigging , where they had just been engaged securing a spar , a number of the s\n",
      "rtions of Starbuck and Stubb -- one engaged forward and the other aft -- the sh\n",
      "hree of the stranger ' s boats were engaged with a shoal of whales , which had \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "word = 'engaged'\n",
    "\n",
    "print(sense.concordance(word))\n",
    "print(moby.concordance(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Read the BBC News article: UK's Vicky Pollards 'left behind' http://news.bbc.co.uk/1/hi/education/6173441.stm. The article gives the following statistic about teen language: \"the top 20 words used, including yeah, no, but and like, account for around a third of all words.\" How many word types account for a third of all word tokens, for a variety of text sources? What do you conclude about this statistic? Read more about this on LanguageLog, at  http://itre.cis.upenn.edu/~myl/languagelog/archives/003993.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part\n",
      "join\n",
      "lol\n",
      "you\n",
      "to\n",
      "the\n",
      "hi\n",
      "me\n",
      "...\n",
      "is\n",
      "in\n",
      "..\n",
      "and\n",
      "it\n",
      "action\n",
      "hey\n",
      "that\n",
      "my\n",
      "of\n",
      "what\n",
      "'s\n",
      "for\n",
      "on\n",
      "here\n",
      "no\n",
      "do\n",
      "are\n",
      "not\n",
      "have\n",
      "....\n",
      "all\n",
      "(31, 0.00511045169798879)\n",
      "to\n",
      "the\n",
      "of\n",
      "and\n",
      "her\n",
      "in\n",
      "was\n",
      "it\n",
      "she\n",
      "that\n",
      "be\n",
      "for\n",
      "not\n",
      "as\n",
      "you\n",
      "he\n",
      "his\n",
      "had\n",
      "(18, 0.0026342748426752523)\n",
      "the\n",
      "of\n",
      "and\n",
      "to\n",
      "in\n",
      "that\n",
      "his\n",
      "it\n",
      "he\n",
      "but\n",
      "as\n",
      "is\n",
      "with\n",
      "was\n",
      "for\n",
      "all\n",
      "this\n",
      "at\n",
      "whale\n",
      "by\n",
      "not\n",
      "(21, 0.0010871253300201895)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "\n",
    "def count_words_in_top(words, percentage):\n",
    "    words = [w for w in words if len(w) > 1]\n",
    "    fd = nltk.FreqDist(w.lower() for w in words)\n",
    "    word_list = sorted(fd, key = fd.get, reverse = True)\n",
    "    \n",
    "    n_all = len(words)\n",
    "    n_sofar = 0\n",
    "    i = 0\n",
    "    while n_sofar < percentage*n_all:\n",
    "        print(word_list[i])\n",
    "        n_sofar = n_sofar + fd[word_list[i]]\n",
    "        i = i + 1\n",
    "    \n",
    "    return(i)\n",
    "    \n",
    "def count_perc(words, percentage):\n",
    "    n_top = count_words_in_top(words, percentage)\n",
    "    n_all = len(set(words))\n",
    "    return(n_top, n_top/n_all)\n",
    "\n",
    "chat = nps_chat.words()\n",
    "print(count_perc(chat, 0.3))\n",
    "print(count_perc(sense, 0.3))\n",
    "print(count_perc(moby, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11\\. Investigate the table of modal distributions and look for other patterns. Try to explain them in terms of your own impressionistic understanding of the different genres. Can you find other closed classes of words that exhibit significant differences across different genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  can could   may might  must  will \n",
      "           news    93    86    66    38    50   389 \n",
      "       religion    82    59    78    12    54    71 \n",
      "        hobbies   268    58   131    22    83   264 \n",
      "science_fiction    16    49     4    12     8    16 \n",
      "        romance    74   193    11    51    45    43 \n",
      "          humor    16    30     8     8     9    13 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre, word)\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
